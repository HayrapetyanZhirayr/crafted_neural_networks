{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'mlp_utils' from '/home/whoisjiji/Desktop/crafted_neural_networks/mlp_utils.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mlp_utils\n",
    "from mlp_utils import Dense, ReLU, LogSoftMax, NNetwork\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "reload(mlp_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_minibatches(inputs, labels, batchsize, shuffle=True):\n",
    "    if shuffle:\n",
    "        indices = np.random.permutation(len(labels))\n",
    "    else:\n",
    "        indices = np.arange(len(labels))\n",
    "    for start_idx in range(0, len(labels), batchsize):\n",
    "        batch_indices = indices[start_idx : start_idx + batchsize]\n",
    "        \n",
    "        yield inputs[batch_indices], labels[batch_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating random data\n",
    "np.random.seed(2)\n",
    "dataset_size = 10**5\n",
    "nclasses = 4\n",
    "X = np.random.randn(dataset_size, 7*7)\n",
    "Y = np.random.randint(low=0, high=nclasses-1, size=dataset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.01\n",
    "input_size = np.prod(X.shape[1:]) ## skipping batch dim\n",
    "model = NNetwork(layers = [\n",
    "    Dense(input_size, 2**5, LR),\n",
    "    ReLU(),\n",
    "    Dense(2**5, 2**4, LR),\n",
    "    ReLU(),\n",
    "    Dense(2**4,nclasses, LR),\n",
    "],\n",
    "    loss = LogSoftMax()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.21340989,  0.39631291, -0.86856653, ..., -1.29404792,\n",
       "        -1.12570562,  1.29092966],\n",
       "       [-0.23899517, -0.19442405,  2.20356364, ...,  1.4954862 ,\n",
       "        -0.29619121, -0.60087935],\n",
       "       [ 1.84882381,  0.83582694,  0.60435625, ...,  0.09464683,\n",
       "         0.25997608, -1.61041033],\n",
       "       ...,\n",
       "       [ 1.75351663,  1.2794048 , -0.1313487 , ...,  1.08061383,\n",
       "         0.89395252, -0.98280237],\n",
       "       [-1.54338587,  0.56257521, -0.08125299, ..., -0.49492859,\n",
       "        -0.83264532, -1.22570946],\n",
       "       [ 0.75284819,  1.86935144, -1.14968957, ...,  0.10486069,\n",
       "         0.0470952 ,  1.07654599]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "train_log = []\n",
    "val_log = []\n",
    "\n",
    "EPOCHS = 1\n",
    "BATCHSIZE = 64\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    for x_batch, y_batch in iterate_minibatches(X, Y, BATCHSIZE):\n",
    "        layer_inputs, logits = model.forward(x_batch) # FORWARD PASS\n",
    "        \n",
    "        \n",
    "        # ENDING FORWARD (COMPUTING LOSS) + STARTING BACKWARD (COMPUTING LOGITS GRAD)\n",
    "        batch_loss, grad_logits = model.compute_loss(logits, y_batch)\n",
    "        \n",
    "        break\n",
    "        \n",
    "  \n",
    "        model.backward(layer_inputs, grad_logits)  # BACKWARD (UPDATING weights)\n",
    "        \n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262.60057351515405"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # grad_output = grad_logits\n",
    "# input, layer = list(reversed(list(zip(layer_inputs, model.layers))))[4]\n",
    "# grad_output = layer.backward(input, grad_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5892453699373856"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102.09045600183748"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.loss.forward(logits, y_batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
